---
title: "Classification-Task"
author: "JoshuaGK"
date: "2023-11-19"
output: html_document
---
```{r}
# install.packages("rBayesianOptimization")
library(randomForest)
library(e1071)
library(rBayesianOptimization)
library(pROC)
library(ROCR)
library(ranger)
library(xgboost)
library(mice)
```

First we load the data
```{r}
useImputed <- TRUE

if (useImputed) {
  num_imp = 3
  data.not_test <- read.csv("cs-training.csv")
  data.test <- read.csv("cs-test.csv")
  # Remove the index column so we don't overfit
  column_to_remove <- "X"
  column_to_remove_2 <- "SeriousDlqin2yrs"
  
  data.not_test <- data.not_test[,-which(names(data.not_test) == column_to_remove)]
  data.imputed.not_test <- mice(data.not_test, m=num_imp, method='pmm', seed=47, printFlag=FALSE)
  data.not_test <- complete(data.imputed.not_test, 1)
  
  data.test <- data.test[,-which(names(data.test) == column_to_remove)]
  data.test <- data.test[,-which(names(data.test) == column_to_remove_2)]
  data.imputed.test <- mice(data.test, model=data.imputed.not_test)
  data.test <- complete(data.imputed.test, 1)
  data.test.full <- complete(data.imputed.test, 1)
  
  print(dim(data.not_test))
  print(dim(data.test))
} else {
  data.not_test <- read.csv("cs-training.csv")
  data.test <- read.csv("cs-test.csv")
  # Remove the index column so we don't overfit
  column_to_remove <- "X"
  column_to_remove_2 <- "SeriousDlqin2yrs"
  data.not_test <- data.not_test[,-which(names(data.not_test) == column_to_remove)]
  data.test <- data.test[,-which(names(data.test) == column_to_remove)]
  data.test <- data.test[,-which(names(data.test) == column_to_remove_2)]
  
  print(dim(data.not_test))
  print(dim(data.test))
  
  # Next we remove the na values
  data.not_test <- na.omit(data.not_test)
  data.test <- na.omit(data.test)
  
  print(dim(data.not_test))
  print(dim(data.test))
}

```
For the purpose of testing, we will use a much smaller size of the data
```{r}
set.seed(47)
sandbox_size <- 0.05
num_rows <- nrow(data.not_test)
data.not_test <- data.not_test[1:round(sandbox_size*num_rows),]
data.not_test <- sample(nrow(data.not_test))
num_rows_test <- nrow(data.test)
data.test <- data.test[1:round(sandbox_size*num_rows_test),]
data.test <- sample(nrow(data.test))
print(dim(data.not_test))
print(dim(data.test))
```

Next we split the data into train and validation sets.
```{r}
train_size = 0.7
split <- round(nrow(data.not_test)*train_size)
num_rows <- nrow(data.not_test)

data.train <- data.not_test[1:split,]
data.train_labels <- data.not_test[1:split,which(names(data.train) == column_to_remove_2)]
data.train_no_labels <- data.not_test[1:split,-which(names(data.train) == column_to_remove_2)]
data.cv <- data.not_test[(split+1):num_rows,] # For some reason, matrix splicing is inclusive on both sides [start, end] not [start, end)

print(dim(data.train))
print(dim(data.cv))
```
Now we create a function to get the accuracy of our model on the test_data
```{r}
get_accuracy <- function(model, test_data) {
  prediction <- predict(model, test_data)
  confusion_matrix <- table(prediction, test_data$SeriousDlqin2yrs)
  accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
  return (accuracy)
}
```

Now we want to train a decision tree classifier using our cross validation set
```{r}
rf_model <- randomForest(factor(SeriousDlqin2yrs) ~ ., data = data.train, ntree=500)

accuracy <- get_accuracy(rf_model, data.cv)
print(accuracy)

```
Now we create an svm classifier
```{r}
svm_model <- svm(factor(SeriousDlqin2yrs) ~ ., data=data.train, kernel="radial", cost = 4, gamma = 0.5)
accuracy_svm <- get_accuracy(svm_model, data.cv)
print(accuracy_svm)
```
Now we test out the bayesian optimization package:
```{r}
# print(data.train_labels)
data <- data.train_no_labels
y <- data.train_labels 
b <- sample(1:length(y)) 
data <- data[b,]
y <- y[b]
y <- as.factor(y)

svm.cv1 <- function(gamma, cost) {
  n <- nrow(data)
  splits <- c(seq(1,n, n/10),n+1)
  jumps <- n/10
  fitted <- c()
  for (i in 1:10) {
    test <- splits[i:(i+1)]
    test[2] <- test[2]-1
    test.y <- as.factor(y[test[1]: test[2]])
    # print(test.y)
    test.data <- data.frame(y=test.y, data[test[1]:test[2],])
    
    train <- (1:n)[-(test[1]:test[2])]
    train.y <- as.factor(y[-(test[1]:test[2])])
    train.data <- data.frame(y=train.y,data[train,])

    fit <- svm(y~., data=train.data, kernel="radial", gamma=gamma, cost=cost, probability=TRUE)
    predictions <- predict(fit, test.data, decision.values=TRUE, probability=TRUE)
    decisions_attr <- attributes(predictions)$decision
    # [, 1] corresponds to the column predicting 0 and 1 corresponds to the column predicting 1
    probabilities <- as.numeric(as.character(attributes(predictions)$probabilities[,1]))
    # decisions <- as.numeric(as.character(predictions))
    # decisions <- ifelse(decisions > 0, 0, 1)
    fitted <- c(fitted, probabilities)
    # print("Y")
    # print(y)
    # print("probabilities")
    # print(probabilities)
    # print("predictions")
    # print(decisions)
    # print("decisions")
    # print(decisions_attr)
    # print("attributes")
    # print(attributes(predictions))
    # print(as.numeric(as.character(predictions)))
    # print(attributes(predict(fit, test.data, decision.values=TRUE))$decision)
    # print(length(y))
    # print(length(fitted))
    # print(attributes(predict(fit, test.data, decision.values=TRUE)))
  }
  # print("fitted")
  # print(fitted)
  return(list(Score=roc(y,fitted)$auc, Pred=0))
}
# test <- svm.cv1(0.377, 508)
bayesian_optimized_svm <- BayesianOptimization(svm.cv1, bounds=list(gamma=c(0,5), cost=c(0,50)), init_points=20, n_iter=20 )
```

```{r}
# print(data.train_labels)
data <- data.train_no_labels
y <- data.train_labels #droplevels(iris[51:150,5])
b <- sample(1:length(y)) 
data <- data[b,]
y <- y[b]
y <- as.factor(y)

rf_objective <- function(ntree, mtry) {
  n <- nrow(data)
  splits <- c(seq(1,n, n/10),n+1)
  jumps <- n/10
  fitted <- c()
  for (i in 1:10) {
    test <- splits[i:(i+1)]
    test[2] <- test[2]-1
    test.y <- as.factor(y[test[1]: test[2]])
    # print(test.y)
    test.data <- data.frame(y=test.y, data[test[1]:test[2],])
    
    train <- (1:n)[-(test[1]:test[2])]
    train.y <- as.factor(y[-(test[1]:test[2])])
    train.data <- data.frame(y=train.y,data[train,])

    # fit <- randomForest(y~., data=train.data, ntree=ntree, mtry=mtry)
    # pred <- predict(fit, test.data, type="response")
    # pred_list <- as.numeric(as.character(pred))
    
    fit <- ranger(y~., data=train.data, num.trees=ntree, mtry=mtry, probability=TRUE)
    pred <- predict(fit, test.data)
    # probability in column 1 is for 0, column 2 is for 1
    probabilities <- pred$predictions[,2]
    # pred_list <- as.numeric(as.character(pred$predictions))
    # print("=======")
    # print(as.numeric(as.character(pred$predictions)))
    # print("=======")
    # print("probabilities")
    # print(probabilities)
    fitted <- c(fitted, probabilities)
  }
  return (list(Score=roc(y,fitted)$auc, Pred=0))
}
# t <- rf_objective(500, 2)
bayesian_optimized_rf <- BayesianOptimization(FUN=rf_objective, bounds=list(ntree=c(500, 750), mtry=c(1,4)), init_points=10, n_iter=20)
```


```{r}
library(mice)
library(e1071)

# Load data
data.train <- read.csv("cs-training.csv")
data.test <- read.csv("cs-test.csv")
data.test$SeriousDlqin2yrs <- NULL

# Parameters
num_imp <- 11
ntree <- 576.2141	
mtry <- 1.610268	
subset_size <- 0.10 # Using first 10% of the training data

# Impute data
set.seed(47)
imputed_data_train <- mice(data.train, m=num_imp, method='pmm', printFlag=FALSE)
imputed_data_test <- mice(data.test, m=num_imp, method='pmm', printFlag=FALSE)
```
Now, to train an svm on each of these imputed sets, and generate a probability of deliquincy for each, then average those probabilities.

```{r}
# Initialize a list to store probability values from all imputations
probability_values_list <- vector("list", num_imp)

# Loop through each imputation
for(i in 1:num_imp) {
    # Get the ith imputed dataset
    imputed_train <- complete(imputed_data_train, i)
    imputed_test <- complete(imputed_data_test, i)

    # Subset the training data
    subset_train <- imputed_train[1:(nrow(imputed_train) * subset_size), ]

    # Train the SVM model with probability estimates
    rf_model <- ranger(factor(SeriousDlqin2yrs) ~ . - X, data = subset_train, probability = TRUE, num.trees =ntree, mtry = mtry)

    # Predict probabilities for ith imputation
    rf_prediction <- predict(rf_model, imputed_test)
    
    # Extract probabilities
    prob_values <- rf_prediction$predictions[,2] # attr(rf_prediction, "probabilities")
    # print(prob_values)
    # Check if the structure is as expected, and extract the relevant probabilities
    positive_class_probabilities <- prob_values
    probability_values_list[[i]] <- positive_class_probabilities
  
}

# Convert list to matrix and calculate average probability
average_probabilities_matrix <- do.call(cbind, probability_values_list)
average_probabilities <- rowMeans(average_probabilities_matrix, na.rm = TRUE)
```

```{r}
# Create a data frame with Id and Probability columns
data <- data.frame(
  Id = 1:length(average_probabilities),
  Probability = average_probabilities
)

# Create a filename string with gamma and cost values
filename <- paste0("output_ntree_", ntree, "_mtry_", mtry, "_imp_", num_imp, ".csv")

# Write the data frame to a CSV file with the new filename
write.csv(data, filename, row.names = FALSE)
```



