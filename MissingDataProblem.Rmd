---
title: "MissingDataProblem"
author: "Mo Kyn"
date: "2023-11-19"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Missing Data Problem
This R Markdown file holds to code necessary to fill in the missing data in the training and test datasets.
We are using the mice package by recommendation of Prof Chandler.

```{r}
require(mice)
```

```{r}
data.train <- read.csv("cs-training.csv")
data.test <- read.csv("cs-test.csv")
```

The columns that we need to fill in missing values for are:

```{r}
na_columns <- colSums(is.na(data.train)) > 0
na_column_names <- names(data.train)[na_columns]
na_column_names
```

```{r}
imputed_data <- mice(data.train, m=20, method='pmm', seed=47, printFlag=FALSE)
```


```{r}
plot(imputed_data)
```
```{r}
for(i in 1:20) {  # If you have 20 imputed datasets
  complete_data <- complete(imputed_data, action = i)
  filename <- paste0("imputed_data/imputed_data_", i, ".csv")  # creates a unique filename for each dataset
  write.csv(complete_data, file = filename, row.names = FALSE)
}
```
```{r}
data.train
```

```{r}
summary(imputed_data)
```
It seems like the most common approach is to train seperate models, then combine our result. So, we can train a random forest classification model on each of the 20 imputed datasets. For test data, the 20 models will "vote" on the classification result.
